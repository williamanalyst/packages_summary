# Data Modelling:

################################################################################################
# Machine Learning
################################################################################################
# Machine Learning --> use algorithms to find patterns and generate models without human intenvision

################################################################################################
# Supervised Machine Learning
################################################################################################
# Supervised Machine Learning --> target variables and input variables are known --> algorithm generates a model that establish relationship between input and target
    # e.g. decision tree
    
#
################################################################################################
# Unsupervised Machine Learning
################################################################################################
# Unsupervised Machine Learning --> identify 1 or mre homogeneous segments/ subsets of the data based on:
    # 1. the degree of similarity among observations/ inputs
    # 2. how many subsets there should be
    # 3. how common or rare the subsets are --> 

################################################################################################
# Clustering Analysis: (e.g. for customer segmentation)
################################################################################################
# Centroid Clustering:
    # Choose the number of clusters we are expecting. (e.g. K-Means)
        # e.g. cat/ dog --> 2 centroids
        # calculate how far away each observation is from the centroids selected.
        # recalculate the centroids until the classification is stable
# Density Clustering:
    # Group observations based on how closely (high density) they are related to each other.
        # Step 1: select a random point
        # Step 2: get a number of observations into a group if the 
# Distribution Clustering:
    # Possibility that each observation would belong to the different clusters.
# Connectivity Clustering: 



################################################################################################
# Hierarchical Clustering: (often visualized using heatmap)
################################################################################################
# Step 1: Find the distance between each data point and its nearest neighbor (and rank them)
# Step 2: Linking the most nearby neighbors (and form smaller subgroups)
    # The number of subgroups could be selected by using the demdrogram
        # Dendrogram is a tree-graph that is commonly used for visualizing taxonomies, lineage and relatedness.

# 


################################################################################################
# Heatmap:
################################################################################################



################################################################################################
# Reinforcement Machine Learning
################################################################################################
# Reinforcement Machine Learning --> reward for correct & punish for error --> improving with more and more tests/ trials
    # 






################################################################################################
# Combine Cluster Analysis and Decision Trees together:
################################################################################################
# 1. 
# 2. 
# 3. 
# 4. categorical data/ variables are usually easier to obtain --> e.g. gender, zip code, education, number of dependents, etc.

# 


################################################################################################
# BIRCH/ 2-step model:
################################################################################################
# e.g. recommend the best number of clusters (default is BIC criterion)







