import pandas as pd
pd.set_option('display.max_columns', 100, 'display.max_rows', 200)
from IPython.display import display # for better formatted tables to be displayed
# 
df.describe()
df.shape
df.dtypes
#
############################################################################################
# loading data
df = pd.read_csv('sample_file.csv') # comma separated file
df = pd.read_csv('sample_file2.txt', sep = '\t') # tab separated file
df = pd.read_csv('https://www.test.com/datafile.data', header = None, names = ['co11', 'col2', 'col3']) # if the table does not have a header
#
df = pd.read_excel('sample_file2.xlsx', sheet_name = 'sheet2', na_value = 'Missing_Value', skiprows = 2,
	dtype = {'column_name1': 'str', 'column_name2': 'float'})
# rename column names
df.rename(columns = {'col1': 'renamed1', 'col2': 'renamed2'}, inplace = True)

############################################################################################
# filter dataframe with .loc
df_t11 = df.loc[(df['column1'] >= 1) & (df['column2'] == 'text') | (df['column3'] < 5)]



# groupby by and aggregate by function
df.groupby(['column1', 'column2'], as_index = False).agg({'column11': 'count', 'column12': 'sum', 'column13': 'nunique', 
  'column14': 'mean', 'column15': 'min', 'column16': 'max'})
#
# Get the max value in each column
max_values = df.max(axis = 1, skimna = False)
print(max_values)

# Get the max value in each column in each group



############################################################################################
# .pct_change()

############################################################################################
# append data to existing dataframe
#
df = df.append({'col1': value1, 'col2': 'str2'}, ignore_index = True)
#
#
############################################################################################
# Drop Columns:
	# 
#
#
############################################################################################
# .shift() to apply either lag or ahead
df['col1_lag1'] = df.groupby(['group_col'])['col1'].shift(1)
df['col1_lead1'] = df.groupby(['group_col'])['col1'].shift(-1)

############################################################################################
# pivot_table
df_pivot = pd.pivot_table(df, index = ['index_row'], columns = ['index_column'], 
    values = ['col_agg1', 'col_agg2'], aggfunc = {'col_agg1': 'sum', 'col_agg2': 'mean'})

#
############################################################################################
# Calculation based on columns
df['cal_col'] = df.apply(lambda x: x['col1'] if x['col1'] > x['col2'] else x['col2'], axis = 1)


# subtract 1 dataframe from another dataframe
df1 = pd.DataFrame({'col1': [10, 100, 1000], 'col2': [1, 2, 3]})
df2 = pd.DataFrame({'col1': [10, 100, 1000], 'col2': [100, 10, 1]})
df3 = df1.subtract(df2)
display(df3)


# change integer to string with zero at the beginning (different length)
df1['filled'] = df1['col1'].apply(lambda x: '{0:0>8}'.format(x))

# calculate the number of days between 2 timedelta objects
df['year'] = df['col1'].dt.year
df['date'] = df['col1'].dt.date # this create a string column that keeps only the %Y-%m-%d section of the date column
df['month'] = df['col2'].dt.month # 

#
df['weekday'] = df['col3'].dt.dayofweek # obtain the weekday of the date column
df['days_in_between'] = (df['end_date'] - df['start_date'])/ pd.Timedelta(1, unit = 'd')
df['months_in_between'] = df['date_column'].dt.to_period('M') - certain_date.to_period('M') # returns the number of months from the starting month/ date
#
############################################################################################
# create a date list (list of dates)
date_list = pd.date_range(start = '2020-01-01', end = '2020-12-31')
date_list2 = pd.date_range(start = '2020-01-01', end = '2020-12-31', freq = 'MS') # this creates a Pandas DatetimeIndex object
#


# cut function to divide a dataframe into several groups
df['col1'] = pd.cut(df['col_to_be_divided'], [0, 2, 4, 6, 8]) # based on the list, the array is divided into (a, b], (b, c], etc.

# 
df['sum_all_columns'] = df.apply(sum, axis = 1) # 
df['max_column'] = np.maximum(df['col1'] * 2, df['col2'] + df['col3']) # array conversion


# crosstab function (similar to pivot_table function) 
pd.crosstab(df['col1'], df['col2'], values = df['col2'], aggfunc = 'mean').round()







############################################################################################
# Integration with Plotly
import pandas as pd
pd.options.plotting.backend = 'plotly'
#
df = pd.DataFrame(dict(a = [1, 2, 3], b = [3, 2, 1]))
fig = df.plot()
fig.show()
#
############################################################################################
# Read extremely large files:
records = []
for chunk in pd.read_csv('bigfile.csv', chunksize = 1000):
    result.append(sum(chunk['column_to_be_sumed']))
result = sum(records)
#
############################################################################################
# rolling mean/ average (window function)
df['7_day_rolling'] = df['column1'].rolling(window = 7, center = False).mean()
df['7_day_rolling'] = df['column1'].rolling(window = 7, center = False).sum()
#
df['cumulative_sum'] = df['col1'].cumsum() # 
#
# Calculate the difference with the next (time) period
df['next_minus_current'] = df['col'].diff(1) # equal to t(n) - t(n-1)
df['current_minus_next'] = df['col'].diff(-1)
#

 
