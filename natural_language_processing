#
###############################################################################################
# Natural Language Processing:
###############################################################################################
# Natural language processing refers to the technique that allows computer to understand, analyze, manipulate, and potentially generate human language.



import nltk
nltk.download('punkt') # 
###############################################################################################
# Tokenization:
###############################################################################################
# Tokenization is the process of splitting some string or sentence into a list of words.
    #
###############################################################################################
# Vectorizing:
###############################################################################################
# Vectorization is the process of encoding text as integers to create feature vectors.
    # e.g. 



###############################################################################################
# Stemming:
###############################################################################################
# Stemming is the process of reducing inflection or derived words to their word stem or root.
    # e.g. 
#
###############################################################################################
# Lemmatizing:
###############################################################################################
# Lemmatizing is the process of grouping together the inflected forms of a word so that they can be analyzed as a single term.
    # e.g. 


###############################################################################################
# Other Concepts:
###############################################################################################
# Root Cause:
    # The earliest underlying factor that is contributing to a problem.
# 

# tokenize the sentence
# Stopwords:
    # e.g. but, if, the, etc.


















#
#
#
