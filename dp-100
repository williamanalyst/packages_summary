# DP100 Exam Curriculum
    # 1. Set-up Azure ML Workspace (create ML workspce, manage data objects)
        # Datastore: 
        # Dataset: 
    # 2. Run Experiment and Train Models (create model with Azure ML Designer, run script in ML Workspace, generate metrics, automate training process) 
        #
    # 3. Optimize and Manage models (use automated ML to optimize model, use Hyperdrice to tune parameters, use model explainer to interpret model, manage model)
        #
    # 4. Deploy and Consume Models (create compute production target, deploy model as a service, create pipeline, publish pipeline as a web service)
        # 
# 
######################################################################################################
# Azure ML Workspace (Architecture/ Structure)
    # Managed Resources (compute instance/ cluster)
    # Linked Service (data storage, compute target)
    # Assets (environments, experiments, pipelines, datasets, models, endpoints)
    # Dependencies (Azure Storage Account, Azure container registry, Azure Key Vault, Azure Application Insights)
# 
# 
######################################################################################################
# AI (Artificial Intelligence) = computer performing tasks without being specifically programmed to.
 
# 
# Azure ML service stores metrics and metadata in Azure Cosmo DB instance where all data is encrypted at rest. 
# 
 
# When 2 experiment has the same name, they will be classified under the same experiment, just different runs for the same experiment.
    # e.g. from Run 1 to Run 2 (previous output will not be impacted)
 
# Azure Container Instance

# Endpoint

# Inference Cluster
 
# Resource Group
 
# Azure ML Experiment = named process, usually the running of a script or pipeline, that can generates metrics/ outputs.
    # and can be tracked in the Azure ML workspace
# 
# Azure Cognitive Service
# Azure Data Lake Analytics
# Azue HDInsight with Spark Mlib
# 
######################################################################################################
# Outliers: observations that have much higher distance compared to other observations
    # outliers does impact the prediction/ estimation of the sample/ model
    # outliers could result from human input error, malfunction of measurement equipment, data transmission error, system bebaviour eror,
        # feaudulent behaviour, natural outliers, sampling error, etc.
    # boxplot, histogram and scatterplot are recommended to identify outliers visually
        # as well as percentile analysis (most common method is visualization)
    #
    
# Variables at different scale
    # Normalize the dataset
# Too many variables or curse of dimensionality
    # PCA
# Missing Value in a large dataset
    # replace with MICE
# Unbalanced Dataset (e.g. fraud data)
    # SMOTE
# Merge datasets on column values
    # join data


 
 
 
 
# 
######################################################################################################
# Azure Identity Servive
    # Authentication (credentials, such as username + password) = prove who you are
    # Authorization (grant access based on permission) = what you are allowed to do based on who you are
# 
# Azure Active Directory (ID as a service/ IDaaS)
    # when the service involve both cloud and on-premise, or through external internet, there is not a central location to authenticate users.
        # 
    
# 
    # Single Sign on (SSO) = same access for multiple apps
    # Role-based access 
# 
# Azure Resource Lock (Cannot delete or read only) = 
    # Locks are interited from the parent group/ resource
# 
 
 
######################################################################################################
# Azure Policy 
 
 
# Azure Blueprint 

######################################################################################################
# Gradient Descent
    # Cost Function
 

# Accuracy
# AUC Weighted
# 
 
# Mean Deviation (when the number of observations is small)
# Standard Deviation (when the number of observations is large)
    # describe how the data is distributed around the mean
    # std(x) = [ sum_of_squared_distances/ (n-1) ] ^ 0.5
        # when the mean of 2 datasets are similar, std(x) could be comparable
# Quartile
    # 1st quartile, median, 3nd quartile
    # IQR = Inter Quartile Range = Q3 - Q1
# Skewness
    # Skewness the a measure of the asymmetry of the probablity distribution of a real-valued random variable about its mean.
        # Positive Skewness = Skewed to left, long tail to right = mode < median < mean
        # Negative Skewness = Skewed to right, long tail to left = mean < median < mode
# Kurtosis
    # 
 
######################################################################################################
# Supervised Learning: 
    # Classification
        # Logistic Regression
        #
        # Decision Tree: (could be for both categorical and continuous variables)
            # Boosted Decision Tree: (for classification by regions)
                # 
            # Decision Forest:
            # Decision Jungle:
        #
    # Regression 
        # Linear Regression
            # MAE (Mean Absolute Error)
            # RMSE (Root Mean Squared Error)
                # punish for large errors
            # RAE (Relative Absolute Error): sum(actual_y - predicted_y)/ sum(actual_y - actual_average_y)
            # R-squared: how many % of variation in y is explanined by the variation in x
                # r2 = SSR/ SST
                    # SSR = sum of squared regression = sum(predicted_y - actual_y_mean)^2
                    # SST = sum of squared total = sum(actual_y - actual_y_mean)^2
    #
    # Decision Tree Regression: (divide all the input variables by region, and return: either mean value of that region, or regression line for each region)
        # Threshold
    #
    # 
# Unsupervised Learning: does not use previously known label values to train the model 
    # Clustering:
        # e.g. recommendaiton, market segmentation, social network analysis, image segmentation, detect anomaly, etc.
        # Euclidean Distance = 
    #
    # K-means Clustering: nominate the number of clusters (K) 
        # Centroid: center point of each cluster (each point is assigned to the nearest centroid) 
            # Each centriod is moved to the center of the data points based on the mean distance of all points within that cluster
            # After moving the centroid, some data points may be closer to a differetn centriod (therefore the cluster will be re-assigned for that data point)
            # The centroid movements stop until the clustering is stable or the maximum steps allowed is reached 
    # K-means++ (default in ML studio and an improvement over finding the initial means)
        # Step 1: the 1st cluster center is chosen uniformly at random from the datapoints
        # Step 2: each cluster center is chosen from the remaining datapoints with probablity propotional to its squared distance closest to existing cluster centers
    #
    # K-means++ Fast: (for faster clustering)
    # Evenly
    # 
    # 
    # SVM 
        # Accuracy is more important than the margins in SVM
    # 
# 
# Reinforcement Learning: 
    # 

    # 

#
# Feature Selection
    # for simplification of models so that they could be interpreted and understood more easily
    # for shorter training time
    # for better accuracy
    # for avoiding the curse of dimensionality
    # for enhanced generalization that helps reducing over-fitting
        # Filter-based Method: use the correlation of x1, x2, x3, ... xn to Y, and choose the most relevant/ influential x
            # e.g. Pearson Correlation, Chi-squared, Mutual Information, Fisher Score, etc.
        # Wrapper Method: test with different combinations of x1, x2, x3, ... xn, and choose the combination of variables that has the best performance
            # e.g. accuracy/ precision or RMSE based on different models
            # Forward Selection: add 1 variable after 1 variable
            # Backward Elimination: eliminate 1 variable after 1 variable
            # Recursive Feature Elimination: random select variables in each iteration, keep the most important variables and removes least influential ones.
        # Embedded Method: 

# Impact of Split Percentage:
# Impact of Stratification:
# Low L1 and High L2:
# High L1 and Low L2:
# High L1 and High L2:
# Low L1 and Low L2: 
#
# Recommendation System: predict the rating/ preference that a customer would give to a new item
    # Problem: cold start, same scale judgement (users not having same standard)
    # 
    # Collaborative Filering: (need user preference and much user activities data)
        # Similar action is assumed for people with similar taste/ preference in the past.
    # Content-base Filering: (need item features + need user to like a few items)
        # Similar feature within the items.
    # Popularity Based Filering:
        # Simply recommend what is generally popular.
    # Hybrid System:
        # Matchbox Recommendation System: 
    #
    # Recommender Split:
#
# Natural Language Processing:
    # Step 1: Noise Removal:
        # Stopwords, Stemming (lemma), Upper/Lower case, numbers, special characters (%, $, etc.). duplication, email, url, etc.
        # Need to consider separation in sentence.
        # Tokenization (e.g. did not = did't)
        # Part-of-speech (e.g. build != building)
    # Step 2: Convert into Feature Vectors: (may encounter Curse of dimensionality)
        # Feature Engineering: 
            # Bag of words:
                # based on the occurrance of words
            # N-gram model: (instead of a single word, get 2 words, 3 words as basic components in the feature selection)
                # e.g. Machine ____ (would recommending learning if "leaning" has the highest chance of being mentioned) (based on probablity)
    # Step 3: Train, Score and Deploy Model:
#
# Feature Hashing:
    # fixed-size array:
    # linked list:
    # hashing:
        #
#
# Azure AutoML:
    # Step 1: bring in dataset.
    # Step 2: define goal, constraints, etc.
    # Step 3: auto ML will test available algorithms, compare the accuracy and provide the evaluations.
#
######################################################################################################
# 
######################################################################################################
# Azure ML Studio - Modules
#
# Clean Missing Data:
    # e.g. mean for numeric, mode for string
#
# Edit Metadata:
    # Make string variable to be categorical
#
# Split Data:
#
# Linear Regression:
    # OLS
    # Online Gradient Descent
        # create trainer mode
        # learning rate
        # number of training epochs
        # L2 Regularization Weight
        # Random Seed
#
# Train Model:
    # launch column selector: select target variable
#
# Score Model:
#
# Evaluate Model:
#
# Summarize Data: 
    # gemeral summary of a dataframe (min, max, mean, mode, missing data, etc.)
# Clip Values: 
    # set of threshold
        # 
# MICE: multi-variate imputation using chained equation or multiple imputation by chained equations
    # assuming that the data is missing randomly (not systematically or biased to a reason)
    # Step 1: calculate the mean value based on available data
    # Step 2: replace all missing value with mean
    # Step 3: choose dependent column and restore original (for the 1 column that you would like to fill/ solve)
    # Step 4: apply transformation and create prediction model
    # Step 5: predict missing value and repeat step 3-5 (for other columns with missing value)


# Filter Based Feature Selection
    # corr(x1, y)
# Fisher Linear Discriminant Analysis
# Permutation Feature Importance
#
# Boosted Decision Tree Regression:
    # Parameter Range
    # 
#
# Hyperparameters Tuning/ Tune Model Hyperparameters : (every module has a set of input parameters, called hyperparameters)
    # helps in determining the best possible combination of model parameters to achieved a desicred result
    # 
    # Optimization Tolerance: when a new iteration does not decrease the loss function (e.g. delta loss < 10^-5 )
    # L1 Regularization: (Lasso Regression)
        # Lasso regression can shrink some coefficients to zero, which means performing variable selection
    # L2 Regularization: (Ridge Regression)
        # Ridge regression will shrink all the coefficientby the same scale, which will not eliminate any variable
#
# Partition and Sample:
# 
# 


#
#
# Evaluate Model Module:
    # Confusion Matrix:
        #               Predicted(True)     Predicted(False)
        # Actual(True)  True Positive       False Negative
        # Actual(False) False Positive      True Negative
        # 
        # Matrix: [[TP, FN], [FP, TN]]
        # 
        # Recall = TP/ (TP + FN) = True Positive 
        # 
        # Accuracy = (TP + TN)/ (TP + TN + FP + FN) = total number of accurate predictions/ total number of observations
        # Precision = TP/ (TP + FP) = (Among those classified as True, % accurate) 
        # Recall = TP/ (TP + FN) = (For those that are actually True, % identified as True) 
        # 
        # F1 Score = 2/(1/Accuracy + 1/Precision) = 2/ [(2TP + FP + FN)/TP] = 2TP/ (2TP + FP + FN) = 1/ (1 + FP/ 2TP + FN/ 2TP)
            # F1 Score = Weighted average (Harmonic Mean) of Precision and Recall = 2 * Precision * Recall / (Precision + Recall)
    # AUC = Area Under Curve (e.g. value = 0.8)
        # ROC = Receiver Operating Characteristics
        # ROC Curve = ( FPR on x-axis and TPR on the y-axis )
            # TPR = True Positive Rate = TP / (TP + FN) = Recall
            # FPR = False Positive Rate = FP / (FP + TN) = 
#            
#
# Deploy Web Service: (based on score model)
    # Could choose either REST API or excel file
######################################################################################################
# Question: Introduce Docker for Windows to attendee
    # 
# Question: Select Data Science Environment
    # 
 
# Question: Move large dataset from Azure ML Studio to Weka environment
    # 
    
#   
 
# DSVM (Data Science Virtual Machine)
 
# Question: Classification task, dataset is inbalanced, how to improve classification accuracy?
    # SMOTE (Synthetic Minority Oversampling Technique)
        # 200 SMOTE percentage would increase 1% minority class to around 3% (2/101)


# Azure Cognitive Service: 
# Azure Data Lake Analytics:
# Azure HDInsight with Spark MLLib:
# Azure ML Studio:

# Question: You can move data to and from Azure Blob using different technologies include:
    # Azure Storage Explorer
    # AzCopy
    # Python/ Pyspark
    # SSIS
    
# Question: Moving a large dataset from Azure ML Studio to a Weka environment:
    # Weka: weka is used for visual data mining and machine learning software in Java.
    # 


# Rattle: Rattle is the R analytical tool that gets you started with data analytics and machine learning.


# Caffe2: 
    #
# Ubuntu:

# Question: compute target to deploy the workspace
    # Azure Container Service















 
