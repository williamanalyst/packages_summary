# DP100 Exam Curriculum
    # 1. Set-up Azure ML Workspace (create ML workspce, manage data objects)
        # Datastore: Datastore securely connect to your storage service on Azure without pytting your authentication credentials, 
            # and the integrity of your original data source at risk. They store connection information, like your subscription ID and token authorization
            # in you Azure Key Vault that is associated with this workspace, so you can securely access your storage without having to hard code them in your script.
                # You can create datastores that connect to these Azure store solutions.
            # Azure ML designer will automatically create a datastore named azureml_globaldatasets when you open a sample in the designer homepage.
                # This datastore only contains sample datasets. User should not use this datastore for any confidential data access.
        # Dataset (there are 2 dataset types, based on how users consume them in training; FileDataset and TabularDataset): 
            # FileDataset:
                # A FileDataset references single or multiple files in your datastores or public URLs.
                    # If your data is already cleansed, and ready to use in training experiments, 
                    # you can download or mount the files to your compute as a FileDataset Object.
            # TabularDataset:
    # 2. Run Experiment and Train Models (create model with Azure ML Designer, run script in ML Workspace, generate metrics, automate training process) 
        #
    # 3. Optimize and Manage models (use automated ML to optimize model, use Hyperdrice to tune parameters, use model explainer to interpret model, manage model)
        #
    # 4. Deploy and Consume Models (create compute production target, deploy model as a service, create pipeline, publish pipeline as a web service)
        # 
# 
######################################################################################################
# Azure ML Workspace (Architecture/ Structure)
    # Managed Resources (compute instance/ cluster)
    # Linked Service (data storage, compute target)
    # Assets (environments, experiments, pipelines, datasets, models, endpoints)
    # Dependencies (Azure Storage Account, Azure container registry, Azure Key Vault, Azure Application Insights)
# 
# 
######################################################################################################
# AI (Artificial Intelligence) = computer performing tasks without being specifically programmed to.
 
# 
# Azure ML service stores metrics and metadata in Azure Cosmo DB instance where all data is encrypted at rest. 
# 
 
# When 2 experiment has the same name, they will be classified under the same experiment, just different runs for the same experiment.
    # e.g. from Run 1 to Run 2 (previous output will not be impacted)
 
# Azure Container Instance

# Endpoint

# Inference Cluster
 
# Resource Group
 
# Azure ML Experiment = named process, usually the running of a script or pipeline, that can generates metrics/ outputs.
    # and can be tracked in the Azure ML workspace
# 
# Azure Cognitive Service
# Azure Data Lake Analytics
# Azue HDInsight with Spark Mlib
# 
######################################################################################################
# Outliers: observations that have much higher distance compared to other observations
    # outliers does impact the prediction/ estimation of the sample/ model
    # outliers could result from human input error, malfunction of measurement equipment, data transmission error, system bebaviour eror,
        # feaudulent behaviour, natural outliers, sampling error, etc.
    # boxplot, histogram and scatterplot are recommended to identify outliers visually
        # as well as percentile analysis (most common method is visualization)
#    
# Variables at different scale
    # Normalize the dataset
#
# Too many variables or curse of dimensionality (100 or 1000 variables)
    # too sparse data and low accuracy
    # require high run time
    # may lead to over-fitting
        # Principal Component Analysis (PCA)
            # Create a new set of coordinates for the data
            # Reveals the internal structure of the data that best explains the variance in the data
            # Reduce the dimensionality 
                # Eigenvectors
                # Eigenvalues
#
# Missing Value in a large dataset
    # replace with MICE
# Unbalanced Dataset: presence of minority class in the dataset (e.g. 0.5% fraud, 99.5% without fraud data)
    (e.g. manufacturing defects, rare disease disgnosis, etc.)
    # might have biased predictions
    # might have misleading accuracy
    # Need to either decrease the majority (e.g. Random Under-Sampling) class or increase the minority class (e.g. SMOTE)
        # If we are simply duplicate the minority class, that is likely to cause over-fitting problem.
        # Synthetic Minority OverSampling Technique (SMOTE)
            # Step 1: Identify the feature vector and its nearest neighbor
            # Step 2: Take the difference between the 2 (feature vector and its nearest neighbor)
            # Step 3: Multiply the difference with a random number between 0 and 1
            # Step 4: Identity a new point on the line segment by adding the random number to the feature vector
            # Step 5: Repeat the process for identified feature vectors.
# Merge datasets on column values
    # join data (datasets are related by key columns)
        # types of joins:
            # Inner Join: select only records that exist in both tables
            # Left Outer Join: select all rows in the left table, and some rows from the right table with matched keys
            # Full Outer Join: select all the rows from both tables
            # Left Semi Join: select left table rows and columns only, and the rows must have mathing keys in the right table
#
#  
 
 
 
# 
######################################################################################################
# Azure Identity Servive
    # Authentication (credentials, such as username + password) = prove who you are
    # Authorization (grant access based on permission) = what you are allowed to do based on who you are
# 
# Azure Active Directory (ID as a service/ IDaaS)
    # when the service involve both cloud and on-premise, or through external internet, there is not a central location to authenticate users.
        # 
    
# 
    # Single Sign on (SSO) = same access for multiple apps
    # Role-based access 
# 
# Azure Resource Lock (Cannot delete or read only) = 
    # Locks are interited from the parent group/ resource
# 
 
 
######################################################################################################
# Azure Policy 
 
 
# Azure Blueprint 

######################################################################################################
# Gradient Descent
    # Cost Function
#
# Normalization: a method to standardize the range of independent variables or features of data
    # Variables are fitted within a certain range (generally between 0 and 1, e.g. min-max scaler)
    # applied only on numeric values
    # Z-score
    # Min-Max Scaler
    # Logistic


# Accuracy
# AUC Weighted
# 
 
# Mean Deviation (when the number of observations is small)
# Standard Deviation (when the number of observations is large)
    # describe how the data is distributed around the mean
    # std(x) = [ sum_of_squared_distances/ (n-1) ] ^ 0.5
        # when the mean of 2 datasets are similar, std(x) could be comparable
# Quartile
    # 1st quartile, median, 3nd quartile
    # IQR = Inter Quartile Range = Q3 - Q1
# Skewness
    # Skewness the a measure of the asymmetry of the probablity distribution of a real-valued random variable about its mean.
        # Positive Skewness = Skewed to left, long tail to right = mode < median < mean
        # Negative Skewness = Skewed to right, long tail to left = mean < median < mode
# Kurtosis
    # 
 
######################################################################################################
# Supervised Learning: 
    # Classification
        # Logistic Regression
        #
        # Decision Tree: (could be for both categorical and continuous variables)
            # Boosted Decision Tree: (for classification by regions)
                # 
            # Decision Forest:
            # Decision Jungle:
        #
    # Regression 
        # Linear Regression
            # MAE (Mean Absolute Error)
            # RMSE (Root Mean Squared Error)
                # punish for large errors
            # RAE (Relative Absolute Error): sum(actual_y - predicted_y)/ sum(actual_y - actual_average_y)
            # R-squared: how many % of variation in y is explanined by the variation in x
                # r2 = SSR/ SST
                    # SSR = sum of squared regression = sum(predicted_y - actual_y_mean)^2
                    # SST = sum of squared total = sum(actual_y - actual_y_mean)^2
    #
    # Decision Tree Regression: (divide all the input variables by region, and return: either mean value of that region, or regression line for each region)
        # Threshold
    #
    # 
# Unsupervised Learning: does not use previously known label values to train the model 
    # Clustering:
        # e.g. recommendaiton, market segmentation, social network analysis, image segmentation, detect anomaly, etc.
        # Euclidean Distance = 
    #
    # K-means Clustering: nominate the number of clusters (K) 
        # Centroid: center point of each cluster (each point is assigned to the nearest centroid) 
            # Each centriod is moved to the center of the data points based on the mean distance of all points within that cluster
            # After moving the centroid, some data points may be closer to a differetn centriod (therefore the cluster will be re-assigned for that data point)
            # The centroid movements stop until the clustering is stable or the maximum steps allowed is reached 
    # K-means++ (default in ML studio and an improvement over finding the initial means)
        # Step 1: the 1st cluster center is chosen uniformly at random from the datapoints
        # Step 2: each cluster center is chosen from the remaining datapoints with probablity propotional to its squared distance closest to existing cluster centers
    #
    # K-means++ Fast: (for faster clustering)
    # Evenly
    # 
    # 
    # SVM 
        # Accuracy is more important than the margins in SVM
    # 
# 
# Reinforcement Learning: 
    # 

    # 

#
# Feature Selection
    # for simplification of models so that they could be interpreted and understood more easily
    # for shorter training time
    # for better accuracy
    # for avoiding the curse of dimensionality
    # for enhanced generalization that helps reducing over-fitting
        # Filter-based Method: use the correlation of x1, x2, x3, ... xn to Y, and choose the most relevant/ influential x
            # Pearson Correlation Coefficient (from =1 to +1 )
                # may be impacted significantly by outliers
                # not good for non-linear relationship
        # Chi-squared Test of Independence:
            # evaluate the relationship between 2 categorical variables
                # Step 1: Define Null and Alternative Hypothesis
                    H0: there is no correlationship between the 2 variables (try to reject H0)
                    H1: alternative, there is correlation
                # Step 2: Define Alpha (probablity that H1 is true, e.g. alpha = 5%)
                # Step 3: Calculate the Degree of Freedom 
                    # DOF = (num of rows - 1) * (number of columns - 1) = (2-1) * (3-1) = 2
                # Step 4: State the Decision Rule:
                    # Critical value for chi-squared distribution
                # Step 5: Calculate the Test Statistics:
                    # 
                # Step 6: Results and Consultion:
                    # if chi-squared value exceeds the limit, reject H0
        # Kendall Correlation Rank Correlation:
            # 
            # e.g. Pearson Correlation, Chi-squared, Mutual Information, Fisher Score, etc.
        #
        # Wrapper Method: test with different combinations of x1, x2, x3, ... xn, and choose the combination of variables that has the best performance
            # e.g. accuracy/ precision or RMSE based on different models
            # Forward Selection: add 1 variable after 1 variable
            # Backward Elimination: eliminate 1 variable after 1 variable
            # Recursive Feature Elimination: random select variables in each iteration, keep the most important variables and removes least influential ones.
        # Embedded Method: 

# Impact of Split Percentage:
# Impact of Stratification:
# Low L1 and High L2:
# High L1 and Low L2:
# High L1 and High L2:
# Low L1 and Low L2: 
#
# Recommendation System: predict the rating/ preference that a customer would give to a new item
    # Problem: cold start, same scale judgement (users not having same standard)
    # 
    # Collaborative Filering: (need user preference and much user activities data)
        # Similar action is assumed for people with similar taste/ preference in the past.
    # Content-base Filering: (need item features + need user to like a few items)
        # Similar feature within the items.
    # Popularity Based Filering:
        # Simply recommend what is generally popular.
    # Hybrid System:
        # Matchbox Recommendation System: 
    #
    # Recommender Split:
    #
# Azure ML Matchbox Recommender System:
    # Based on the Hybrid approach of content and collaborative filering technique
        # When customers are new, rely on item feature
        # When customers have sufficient activities, use activities as well
    # Require user-item-rating triples and, optionally, somer user and item features.
        # First Input: (mandatory)
            # Column 1: User Identifier
            # Column 2: Item Identifier
            # Column 3: Rating for the User-Item pair (has to be either numeric or categorical)
        # Second Input: (Optional)
            # User ID and the user Features (1st column must be User ID if not blank here)
        # Third Input: (Optional)
            # Item ID and Item features (1st column must be Item ID if not blank here)
    # Number of Traits:
        # How many traits to learn for each user and item
        # Each feature is associated with a latent "trait" vector
    # Number of Recommendation Algorithm Iterations:
        # How many times that the algorithm should process the data
            # recommended 5-10
    # Number of Training Batches:
        # Number of batches for dividing the data into during training
#
# Natural Language Processing:
    # Step 1: Noise Removal:
        # Stopwords, Stemming (lemma), Upper/Lower case, numbers, special characters (%, $, etc.). duplication, email, url, etc.
        # Need to consider separation in sentence.
        # Tokenization (e.g. did not = did't)
        # Part-of-speech (e.g. build != building)
    # Step 2: Convert into Feature Vectors: (may encounter Curse of dimensionality)
        # Feature Engineering: 
            # Bag of words:
                # based on the occurrance of words
            # N-gram model: (instead of a single word, get 2 words, 3 words as basic components in the feature selection)
                # e.g. Machine ____ (would recommending learning if "leaning" has the highest chance of being mentioned) (based on probablity)
    # Step 3: Train, Score and Deploy Model:
#
# Feature Hashing:
    # fixed-size array:
    # linked list:
    # hashing:
        #
#
# Azure AutoML:
    # Step 1: bring in dataset.
    # Step 2: define goal, constraints, etc.
    # Step 3: auto ML will test available algorithms, compare the accuracy and provide the evaluations.
#
######################################################################################################
# Azure ML Studio - Modules
######################################################################################################
# Import Dataset:
# 
# Add Columns:
# Add Rows:
#
# SMOTE
    # Selected Column: 
    # SMOTE percentage: 
    # Number of nearest neighbors:
    # Random Seed: 
#
# Normalize Data:
    # Transformation Method:
    # Selected Column: (numeric only)
#
# Clean Missing Data:
    # Cleaning Mode:
        # Replace using MICE
    # e.g. mean for numeric, mode for string
#
# Edit Metadata:
    # Make string variable to be categorical
#
# Join Data:
    # Selected Key for Left Table:
    # Selected Key for Right Table:
    # Match Case:
    # Join Type:
    # Keep right Key columns in the joined table:
#
# Principal Component Analysis:
    # Select Columns:
    # Number of dimensionality to reduce to:
        # Normalize dense dataset to zero mean
#
# Split Data:
    # Splitting Mode: 
        # split rows:
        # Regular Expression: 
    # Fraction of rows in the 1st split: 0.7
    # Random Seed: 123
    # Stratified Split: False
#
# Linear Regression:
    # OLS
    # Online Gradient Descent
        # create trainer mode
        # learning rate
        # number of training epochs
        # L2 Regularization Weight
        # Random Seed
#
# Train Model:
    # launch column selector: select target variable
#
# Score Model:
#
# Score Mathbox Recommendation:
    (5 inputs: trained matchbox recommender model, dataset to score, user features, item features, training data)
    (can also be used for "people like you" predictions)
    # Recommender Prediction Kind:
        # Predict Ratings: ()
        # Item Recommendation: 
            (from rated items for model evaluation)
            # Generate a list of items that will appeal to each customer
        # 
    # Recommended Item Selection:
    # Maximum Number of Items to Recommend:
    # Minimum size of recommendation pool for a single user:
    # Whether to return predicted 
#
# Evaluate Model:
#
# Summarize Data: 
    # general summary of a dataframe (min, max, mean, mode, number of unique values, missing data count, etc.)
        # Kurtosis, Skewness, Percentile 1, Percentile 95, etc.
# Clip Values: 
    # set of threshold
        # 
# MICE: multi-variate imputation using chained equation or multiple imputation by chained equations
    # assuming that the data is missing randomly (not systematically or biased to a reason)
    # Step 1: calculate the mean value based on available data
    # Step 2: replace all missing value with mean
    # Step 3: choose dependent column and restore original (for the 1 column that you would like to fill/ solve)
    # Step 4: apply transformation and create prediction model
    # Step 5: predict missing value and repeat step 3-5 (for other columns with missing value)


# Filter Based Feature Selection:
    # Feature Scoring Method:
        # Pearson's Correlation:
        # Spearman (relatively more reliable when having some, but not extreme outliers)
        # Kandell: (more reliable when having significant outliers)
    # Target Column:
    # Number of Desired Features:
    # 
    # corr(x1, y)
# Fisher Linear Discriminant Analysis
# Permutation Feature Importance
#
# Boosted Decision Tree Regression:
    # Parameter Range
    # 
#
# Hyperparameters Tuning/ Tune Model Hyperparameters : (every module has a set of input parameters, called hyperparameters)
    # helps in determining the best possible combination of model parameters to achieved a desicred result
    # 
    # Optimization Tolerance: when a new iteration does not decrease the loss function (e.g. delta loss < 10^-5 )
    # L1 Regularization: (Lasso Regression)
        # Lasso regression can shrink some coefficients to zero, which means performing variable selection
    # L2 Regularization: (Ridge Regression)
        # Ridge regression will shrink all the coefficientby the same scale, which will not eliminate any variable
#
# Partition and Sample:
# 
# 
# K-Means Clustering
    # Create Trainer Mode (single parameter)
    # Number of Centroids
    # Initialization (K-Means++, K-Means++ Fast, First N, Forgy Method, Evenly and by Use Label Column.)
        # Use Label Column: use a variable from the existing dataset to guide selection of the centroids.
        # 
    # Random Number Seed:
    # Metric: Euclidean, Cosine
    # Iterations: 
    # Assign Label Mode: 
#
#
# Evaluate Model Module:
    # Confusion Matrix:
        #               Predicted(True)     Predicted(False)
        # Actual(True)  True Positive       False Negative
        # Actual(False) False Positive      True Negative
        # 
        # Matrix: [[TP, FN], [FP, TN]]
        # 
        # Recall = TP/ (TP + FN) = True Positive 
        # 
        # Accuracy = (TP + TN)/ (TP + TN + FP + FN) = total number of accurate predictions/ total number of observations
        # Precision = TP/ (TP + FP) = (Among those classified as True, % accurate) 
        # Recall = TP/ (TP + FN) = (For those that are actually True, % identified as True) 
        # 
        # F1 Score = 2/(1/Accuracy + 1/Precision) = 2/ [(2TP + FP + FN)/TP] = 2TP/ (2TP + FP + FN) = 1/ (1 + FP/ 2TP + FN/ 2TP)
            # F1 Score = Weighted average (Harmonic Mean) of Precision and Recall = 2 * Precision * Recall / (Precision + Recall)
    # AUC = Area Under Curve (e.g. value = 0.8)
        # ROC = Receiver Operating Characteristics
        # ROC Curve = ( FPR on x-axis and TPR on the y-axis )
            # TPR = True Positive Rate = TP / (TP + FN) = Recall
            # FPR = False Positive Rate = FP / (FP + TN) = 
#            
#
# Deploy Web Service: (based on score model)
    # Could choose either REST API or excel file
######################################################################################################
# Question: Introduce Docker for Windows to attendee
    # BIOS-enabled visualisation
    # Windows 10 64-bit professional
    
# Question: Select Data Science Environment
    # 
 
# Question: Move large dataset from Azure ML Studio to Weka environment
    # 
    
#   
 
# DSVM (Data Science Virtual Machine)
 
# Question: Classification task, dataset is inbalanced, how to improve classification accuracy?
    # SMOTE (Synthetic Minority Oversampling Technique)
        # 200 SMOTE percentage would increase 1% minority class to around 3% (2/101)


# Azure Cognitive Service: 
# Azure Data Lake Analytics:
# Azure HDInsight with Spark MLLib:
# Azure ML Studio:

# Question: You can move data to and from Azure Blob using different technologies include:
    # Azure Storage Explorer
    # AzCopy
    # Python/ Pyspark
    # SSIS
    
# Question: Moving a large dataset from Azure ML Studio to a Weka environment:
    # Weka: weka is used for visual data mining and machine learning software in Java.
    # 


# Rattle: Rattle is the R analytical tool that gets you started with data analytics and machine learning.


# Caffe2: 
    #
# Ubuntu:

# Question: compute target to deploy the workspace
    # Azure Container Service






# Question: how to deal with new data input that does not exist in the training dataset.
    # 








 
