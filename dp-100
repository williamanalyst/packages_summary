# DP100 Exam Curriculum
    # 1. Set-up Azure ML Workspace (create ML workspce, manage data objects)
        # Datastore: Datastore securely connect to your storage service on Azure without pytting your authentication credentials, 
            # and the integrity of your original data source at risk. They store connection information, like your subscription ID and token authorization
            # in you Azure Key Vault that is associated with this workspace, so you can securely access your storage without having to hard code them in your script.
                # You can create datastores that connect to these Azure store solutions.
            # Azure ML designer will automatically create a datastore named azureml_globaldatasets when you open a sample in the designer homepage.
                # This datastore only contains sample datasets. User should not use this datastore for any confidential data access.
        # Dataset (there are 2 dataset types, based on how users consume them in training; FileDataset and TabularDataset): 
            # FileDataset:
                # A FileDataset references single or multiple files in your datastores or public URLs.
                    # If your data is already cleansed, and ready to use in training experiments, 
                    # you can download or mount the files to your compute as a FileDataset Object.
            # TabularDataset:
    # 2. Run Experiment and Train Models (create model with Azure ML Designer, run script in ML Workspace, generate metrics, automate training process) 
        #
    # 3. Optimize and Manage models (use automated ML to optimize model, use Hyperdrice to tune parameters, use model explainer to interpret model, manage model)
        #
    # 4. Deploy and Consume Models (create compute production target, deploy model as a service, create pipeline, publish pipeline as a web service)
        # 
# 
######################################################################################################
# Azure ML Workspace (Architecture/ Structure)
    # Managed Resources (compute instance/ cluster)
    # Linked Service (data storage, compute target)
    # Assets (environments, experiments, pipelines, datasets, models, endpoints)
    # Dependencies (Azure Storage Account, Azure container registry, Azure Key Vault, Azure Application Insights)
# 
# 
######################################################################################################
# General Concepts
######################################################################################################
# AI (Artificial Intelligence) = computer performing tasks without being specifically programmed to.
# CUDA (Compute Unified Device Architect) 
# 
# Azure ML service stores metrics and metadata in Azure Cosmo DB instance where all data is encrypted at rest. 
# 
 
# When 2 experiment has the same name, they will be classified under the same experiment, just different runs for the same experiment.
    # e.g. from Run 1 to Run 2 (previous output will not be impacted)
 
# Azure Container Instance

# Endpoint

# Inference Cluster
 
# Resource Group
 
# Azure ML Experiment = named process, usually the running of a script or pipeline, that can generates metrics/ outputs.
    # and can be tracked in the Azure ML workspace
# 
# Azure Cognitive Service
# Azure Data Lake Analytics
# Azue HDInsight with Spark Mlib
# 
######################################################################################################
# Outliers: observations that have much higher distance compared to other observations
    # outliers does impact the prediction/ estimation of the sample/ model
    # outliers could result from human input error, malfunction of measurement equipment, data transmission error, system bebaviour eror,
        # feaudulent behaviour, natural outliers, sampling error, etc.
    # boxplot, histogram and scatterplot are recommended to identify outliers visually
        # as well as percentile analysis (most common method is visualization)
#    
# Variables at different scale
    # Normalize the dataset
#
# Too many variables or curse of dimensionality (100 or 1000 variables)
    # too sparse data and low accuracy
    # require high run time
    # may lead to over-fitting
        # Principal Component Analysis (PCA)
            # Create a new set of coordinates for the data
            # Reveals the internal structure of the data that best explains the variance in the data
            # Reduce the dimensionality 
                # Eigenvectors
                # Eigenvalues
#
# Missing Value in a large dataset
    # replace with MICE
# Unbalanced Dataset: presence of minority class in the dataset (e.g. 0.5% fraud, 99.5% without fraud data)
    (e.g. manufacturing defects, rare disease disgnosis, etc.)
    # might have biased predictions
    # might have misleading accuracy
    # Need to either decrease the majority (e.g. Random Under-Sampling) class or increase the minority class (e.g. SMOTE)
        # If we are simply duplicate the minority class, that is likely to cause over-fitting problem.
        # Synthetic Minority OverSampling Technique (SMOTE)
            # Step 1: Identify the feature vector and its nearest neighbor
            # Step 2: Take the difference between the 2 (feature vector and its nearest neighbor)
            # Step 3: Multiply the difference with a random number between 0 and 1
            # Step 4: Identity a new point on the line segment by adding the random number to the feature vector
            # Step 5: Repeat the process for identified feature vectors.
# Merge datasets on column values
    # join data (datasets are related by key columns)
        # types of joins:
            # Inner Join: select only records that exist in both tables
            # Left Outer Join: select all rows in the left table, and some rows from the right table with matched keys
            # Full Outer Join: select all the rows from both tables
            # Left Semi Join: select left table rows and columns only, and the rows must have mathing keys in the right table
#
#  
 
 
 
# 
######################################################################################################
# Azure Identity Servive
    # Authentication (credentials, such as username + password) = prove who you are
    # Authorization (grant access based on permission) = what you are allowed to do based on who you are
# 
# Azure Active Directory (ID as a service/ IDaaS)
    # when the service involve both cloud and on-premise, or through external internet, there is not a central location to authenticate users.
        # 
    
# 
    # Single Sign on (SSO) = same access for multiple apps
    # Role-based access 
# 
# Azure Resource Lock (Cannot delete or read only) = 
    # Locks are interited from the parent group/ resource
# 
 
 
######################################################################################################
# Azure Policy 
 
 
# Azure Blueprint 

######################################################################################################
# Gradient Descent
    # Cost Function
#
# Normalization: a method to standardize the range of independent variables or features of data
    # Variables are fitted within a certain range (generally between 0 and 1, e.g. min-max scaler)
    # applied only on numeric values
    # Z-score
    # Min-Max Scaler
    # Logistic


# Accuracy
# AUC Weighted
# 
 
# Mean Deviation (when the number of observations is small)
# Standard Deviation (when the number of observations is large)
    # describe how the data is distributed around the mean
    # std(x) = [ sum_of_squared_distances/ (n-1) ] ^ 0.5
        # when the mean of 2 datasets are similar, std(x) could be comparable
# Quartile
    # 1st quartile, median, 3nd quartile
    # IQR = Inter Quartile Range = Q3 - Q1
# Skewness
    # Skewness the a measure of the asymmetry of the probablity distribution of a real-valued random variable about its mean.
        # Positive Skewness = Skewed to left, long tail to right = mode < median < mean
        # Negative Skewness = Skewed to right, long tail to left = mean < median < mode
# Kurtosis
    # 
 
######################################################################################################
# Supervised Learning: 
    # Classification
        # Logistic Regression
        #
        # Decision Tree: (could be for both categorical and continuous variables)
            # Boosted Decision Tree: (for classification by regions)
                # 
            # Decision Forest:
            # Decision Jungle:
        #
    # Regression 
        # Linear Regression
            # MAE (Mean Absolute Error)
            # RMSE (Root Mean Squared Error)
                # punish for large errors
            # RAE (Relative Absolute Error): sum(actual_y - predicted_y)/ sum(actual_y - actual_average_y)
            # R-squared: how many % of variation in y is explanined by the variation in x
                # r2 = SSR/ SST
                    # SSR = sum of squared regression = sum(predicted_y - actual_y_mean)^2
                    # SST = sum of squared total = sum(actual_y - actual_y_mean)^2
    #
    # Decision Tree Regression: (divide all the input variables by region, and return: either mean value of that region, or regression line for each region)
        # Threshold
    #
    # 
# Unsupervised Learning: does not use previously known label values to train the model 
    # Clustering:
        # e.g. recommendaiton, market segmentation, social network analysis, image segmentation, detect anomaly, etc.
        # Euclidean Distance = 
    #
    # K-means Clustering: nominate the number of clusters (K) 
        # Centroid: center point of each cluster (each point is assigned to the nearest centroid) 
            # Each centriod is moved to the center of the data points based on the mean distance of all points within that cluster
            # After moving the centroid, some data points may be closer to a differetn centriod (therefore the cluster will be re-assigned for that data point)
            # The centroid movements stop until the clustering is stable or the maximum steps allowed is reached 
    # K-means++ (default in ML studio and an improvement over finding the initial means)
        # Step 1: the 1st cluster center is chosen uniformly at random from the datapoints
        # Step 2: each cluster center is chosen from the remaining datapoints with probablity propotional to its squared distance closest to existing cluster centers
    #
    # K-means++ Fast: (for faster clustering)
    # Evenly
    # 
    # 
    # SVM 
        # Accuracy is more important than the margins in SVM
    # 
# 
# Reinforcement Learning: 
    # 

    # 

#
# Feature Selection
    # for simplification of models so that they could be interpreted and understood more easily
    # for shorter training time
    # for better accuracy
    # for avoiding the curse of dimensionality
    # for enhanced generalization that helps reducing over-fitting
        # Filter-based Method: use the correlation of x1, x2, x3, ... xn to Y, and choose the most relevant/ influential x
            # Pearson Correlation Coefficient (from =1 to +1 )
                # may be impacted significantly by outliers
                # not good for non-linear relationship
        # Chi-squared Test of Independence:
            # evaluate the relationship between 2 categorical variables
                # Step 1: Define Null and Alternative Hypothesis
                    H0: there is no correlationship between the 2 variables (try to reject H0)
                    H1: alternative, there is correlation
                # Step 2: Define Alpha (probablity that H1 is true, e.g. alpha = 5%)
                # Step 3: Calculate the Degree of Freedom 
                    # DOF = (num of rows - 1) * (number of columns - 1) = (2-1) * (3-1) = 2
                # Step 4: State the Decision Rule:
                    # Critical value for chi-squared distribution
                # Step 5: Calculate the Test Statistics:
                    # 
                # Step 6: Results and Consultion:
                    # if chi-squared value exceeds the limit, reject H0
        # Kendall Correlation Rank Correlation:
            # 
            # e.g. Pearson Correlation, Chi-squared, Mutual Information, Fisher Score, etc.
        #
        # Wrapper Method: test with different combinations of x1, x2, x3, ... xn, and choose the combination of variables that has the best performance
            # e.g. accuracy/ precision or RMSE based on different models
            # Forward Selection: add 1 variable after 1 variable
            # Backward Elimination: eliminate 1 variable after 1 variable
            # Recursive Feature Elimination: random select variables in each iteration, keep the most important variables and removes least influential ones.
        # Embedded Method: 

# Impact of Split Percentage:
# Impact of Stratification:
# Low L1 and High L2:
# High L1 and Low L2:
# High L1 and High L2:
# Low L1 and Low L2: 
#
# Recommendation System: predict the rating/ preference that a customer would give to a new item
    # Problem: cold start, same scale judgement (users not having same standard)
    # 
    # Collaborative Filering: (need user preference and much user activities data)
        # Similar action is assumed for people with similar taste/ preference in the past.
    # Content-base Filering: (need item features + need user to like a few items)
        # Similar feature within the items.
    # Popularity Based Filering:
        # Simply recommend what is generally popular.
    # Hybrid System:
        # Matchbox Recommendation System: 
    #
    # Recommender Split:
    #
# Azure ML Matchbox Recommender System:
    # Based on the Hybrid approach of content and collaborative filering technique
        # When customers are new, rely on item feature
        # When customers have sufficient activities, use activities as well
    # Require user-item-rating triples and, optionally, somer user and item features.
        # First Input: (mandatory)
            # Column 1: User Identifier
            # Column 2: Item Identifier
            # Column 3: Rating for the User-Item pair (has to be either numeric or categorical)
        # Second Input: (Optional)
            # User ID and the user Features (1st column must be User ID if not blank here)
        # Third Input: (Optional)
            # Item ID and Item features (1st column must be Item ID if not blank here)
    # Number of Traits:
        # How many traits to learn for each user and item
        # Each feature is associated with a latent "trait" vector
    # Number of Recommendation Algorithm Iterations:
        # How many times that the algorithm should process the data
            # recommended 5-10
    # Number of Training Batches:
        # Number of batches for dividing the data into during training
#
# Natural Language Processing:
    # Step 1: Noise Removal:
        # Stopwords, Stemming (lemma), Upper/Lower case, numbers, special characters (%, $, etc.). duplication, email, url, etc.
        # Need to consider separation in sentence.
        # Tokenization (e.g. did not = did't)
        # Part-of-speech (e.g. build != building)
    # Step 2: Convert into Feature Vectors: (may encounter Curse of dimensionality)
        # Feature Engineering: 
            # Bag of words:
                # based on the occurrance of words
            # N-gram model: (instead of a single word, get 2 words, 3 words as basic components in the feature selection)
                # e.g. Machine ____ (would recommending learning if "leaning" has the highest chance of being mentioned) (based on probablity)
    # Step 3: Train, Score and Deploy Model:
#

#
# Global Feature Importance: based on either training data or test dataset (result from Global and Local Feature Importance may be different)
# Local Feature Importance: based on certain observations only
#
# Azure AutoML:
    # Step 1: bring in dataset.
    # Step 2: define goal, constraints, etc.
    # Step 3: auto ML will test available algorithms, compare the accuracy and provide the evaluations.
#
######################################################################################################
# Azure ML Studio - Modules (should practice 3+ times)
######################################################################################################
# Import Dataset:
# 
# Add Columns:
# Add Rows:
#
# SMOTE
    # Selected Column: 
    # SMOTE percentage: 
    # Number of nearest neighbors:
    # Random Seed: 
#
# Normalize Data:
    # Transformation Method:
    # Selected Column: (numeric only)
#
# Clean Missing Data:
    # Cleaning Mode:
        # Replace using MICE
    # MICE: multi-variate imputation using chained equation or multiple imputation by chained equations
        # Clean the missing value without affecting/ reducing the dimensionality of the feature set.
        # 
        # assuming that the data is missing randomly (not systematically or biased to a reason)
        # Step 1: calculate the mean value based on available data
        # Step 2: replace all missing value with mean
        # Step 3: choose dependent column and restore original (for the 1 column that you would like to fill/ solve)
        # Step 4: apply transformation and create prediction model
        # Step 5: predict missing value and repeat step 3-5 (for other columns with missing value)
            # e.g. mean for numeric, mode for string
#
# Edit Metadata:
    # Make string variable to be categorical
#
# Join Data:
    # Selected Key for Left Table:
    # Selected Key for Right Table:
    # Match Case:
    # Join Type:
    # Keep right Key columns in the joined table:
#
# Principal Component Analysis:
    # Select Columns:
    # Number of dimensionality to reduce to:
        # Normalize dense dataset to zero mean
#
# Split Data:
    # Splitting Mode: 
        # split rows:
        # Regular Expression: 
    # Fraction of rows in the 1st split: 0.7
    # Random Seed: 123
    # Stratified Split: False
#
# Group Data into Bins:
    # 
#
# Latent Direchlet Transformation:
    # Topic Modelling:
# 
# Build Counting Transformation Module:
#
# Missing Value Scrubber (deprecated)
#
# Replace Discrete Values:
    # 
#
######################################################################################################
# Python Language Modules:
    # Python Language Modules:
    # Execute Python Script:
        # With Python, users could perform tasks that are not currently supported by existing ML Studio Modules.
            # e.g. Visualizing data with Matplotlib
            # e.g. Using python libraries to enumerate datasets and models in your workspace
            # e.g. reading, loading, and manipulating data froms sources not supported by the "Import Data" Module
#
# Convert to Indicator Values Module:
    # Use the Convert to Indicator Values module to convert columns that contain categorical values into a series of binray indicator columns
        # that can be used as a series of features in the ML model.
        # (similar to one-hot encoding)
#
# Partition and Sample:
    # Expected Input = Data Table
    # Expected Output = Data Table
        # Filter 1: Partition or Sample Mode:
            #
        # Filter 2: Rate of Sampling:
            #
        # Filter 3: Random Seed for Sampling
            # default to be 0
        # Filer 4: Stratified split for Sampling
            # True/ False
    # Sampling is an important module in ML as it lets you reduce the size of a dataset while maintaining the same ratio of values.
        # Dividing your data into multiple subsections of the same size.
            # e.g. you might use the partition for cross-validation, or to assign cases to random groups
        # Separating data into groups then work with data from a specific group.
            #
        # Sampling.
            # e.g. either by percentage with random sampling, choose a column to use for balancing the dataset, or perform stratified sampling, etc.
        # Creating smaller datasets for testing.
            # e.g. to save processing time during testing
#
# Linear Regression:
    # OLS
    # Online Gradient Descent
        # create trainer mode
        # learning rate
        # number of training epochs
        # L2 Regularization Weight
        # Random Seed
#
#
# Train Model:
    # launch column selector: select target variable
#
# Score Model:
#
# Score Mathbox Recommendation:
    (5 inputs: trained matchbox recommender model, dataset to score, user features, item features, training data)
    (can also be used for "people like you" predictions)
    # Recommender Prediction Kind:
        # Predict Ratings: ()
        # Item Recommendation: 
            (from rated items for model evaluation)
            # Generate a list of items that will appeal to each customer
        # 
    # Recommended Item Selection:
    # Maximum Number of Items to Recommend:
    # Minimum size of recommendation pool for a single user:
    # Whether to return predicted 
#
# Evaluate Model:
#
# Export Count Table Module:
    # 
#
# Summarize Data: 
    # general summary of a dataframe (min, max, mean, mode, number of unique values, missing data count, etc.)
        # Kurtosis, Skewness, Percentile 1, Percentile 95, etc.
        # e.g. how many missing values are there in each column
        # e.g. how many unique values are there in each feature column
        # e.g. what is the mean and standard deviation of each numeric column
#
# Clip Values: 
    # set of threshold
        # 
#
# Feature Hashing:
    # Feature hashing is used for linguistics, and works by converting unique tokens into unique integers.
    #
    # fixed-size array:
    # linked list:
    # hashing:
        #
#
# Filter Based Feature Selection:
    # Feature Scoring Method:
        # Pearson's Correlation:
        # Spearman (relatively more reliable when having some, but not extreme outliers)
        # Kandell: (more reliable when having significant outliers)
    # Target Column:
    # Number of Desired Features:
    # 
    # corr(x1, y)
# Fisher Linear Discriminant Analysis
# Permutation Feature Importance
#
# Boosted Decision Tree Regression:
    # Parameter Range
    # 
#
# Hyperparameters Tuning/ Tune Model Hyperparameters : (every module has a set of input parameters, called hyperparameters)
    # helps in determining the best possible combination of model parameters to achieved a desicred result
    # 
    # Optimization Tolerance: when a new iteration does not decrease the loss function (e.g. delta loss < 10^-5 )
    # L1 Regularization: (Lasso Regression)
        # Lasso regression can shrink some coefficients to zero, which means performing variable selection
    # L2 Regularization: (Ridge Regression)
        # Ridge regression will shrink all the coefficientby the same scale, which will not eliminate any variable
#
# Partition and Sample:
# 
# Convert to ARFF: 
    # Convert datasets and results in Azure ML to attribute-relation file format (ARFF) used by the Weka toolset.
    # The ARFF data specification for Weka supports multiple ML tasks, including data preprocessing, classification, and feature selection.
        # In ARFF format, data is organized by entities and their attributes, and is contained in a single text file.
# 
# K-Means Clustering
    # Create Trainer Mode (single parameter)
    # Number of Centroids
    # Initialization (K-Means++, K-Means++ Fast, First N, Forgy Method, Evenly and by Use Label Column.)
        # Use Label Column: use a variable from the existing dataset to guide selection of the centroids.
        # 
    # Random Number Seed:
    # Metric: Euclidean, Cosine
    # Iterations: 
    # Assign Label Mode: 
#
#
# Evaluate Model Module:
    # Confusion Matrix:
        #               Predicted(True)     Predicted(False)
        # Actual(True)  True Positive       False Negative
        # Actual(False) False Positive      True Negative
        # 
        # Matrix: [[TP, FN], [FP, TN]]
        # 
        # Recall = TP/ (TP + FN) = True Positive 
        # 
        # Accuracy = (TP + TN)/ (TP + TN + FP + FN) = total number of accurate predictions/ total number of observations
        # Precision = TP/ (TP + FP) = (Among those classified as True, % accurate) 
        # Recall = TP/ (TP + FN) = (For those that are actually True, % identified as True) 
        # 
        # F1 Score = 2/(1/Accuracy + 1/Precision) = 2/ [(2TP + FP + FN)/TP] = 2TP/ (2TP + FP + FN) = 1/ (1 + FP/ 2TP + FN/ 2TP)
            # F1 Score = Weighted average (Harmonic Mean) of Precision and Recall = 2 * Precision * Recall / (Precision + Recall)
    # AUC = Area Under Curve (e.g. value = 0.8)
        # ROC = Receiver Operating Characteristics
        # ROC Curve = ( FPR on x-axis and TPR on the y-axis )
            # TPR = True Positive Rate = TP / (TP + FN) = Recall
            # FPR = False Positive Rate = FP / (FP + TN) = 
#            
#
# Deploy Web Service: (based on score model)
    # Could choose either REST API or excel file
######################################################################################################
# Exam Structure:
######################################################################################################
# Exam Questions:
    #
# Question: 
    # Data Engineering and Data Science Environment:
        # Support Python and Scala 
            # Azure Databricks
        # Compose data storage, movement and processing service into automated data pipelines
            # Azure Data Factory
        # The same tool should be used for the orchestration of both data engineering and data science
        # Support workload isolation and interactive workloads
        # enable scaling across a cluster of machines
            # Azure Databricks/ Azure ML Studio
        # You need to create the environment: should build the environment in Azure Databricks and use Azure Data Factory for orchestration.
            # Apache Spark: support Python, R, Scala, SQL
            # High concurrency: Azure Databricks is fully integrated with Azure Data Factory.
                # Azure Container: Azure Container is good for development and testing, not suitable for production workloads.
#
# Question: Introduce Docker for Windows to attendee
    # BIOS-enabled (Basic Input-Output System) virtualization
        # Must make sure that the machine supports Hardware Virtualization and that Virtualization is enabled.
    # Windows 10 64-bit professional
        # To run Docker, your machine must have a 64-bit operating system running Windows 7 or higher.
    
# Question: Select Data Science Environment
    # Azure Cognitive Services:
        # Azure Cognitive Serviers expand on Microsoft's evolving portfolio of ML APIs ane enable developers to easily add cognitive features:
            # e.g. emotion and video detection, facial, speech, and vision recognition; and speech and language understanding into applications.
            # Azure Cognitive Services can be categorized into 5 main pillars: Vision, Speech, Language, Search and knowledge.
    # Azure Data Lake Analytics:
    # Azure HDInsight with Spark MLLib:
    # Azure ML Studio: 
 
# Question: Move large dataset from Azure ML Studio to Weka environment
    # 
    
#   
# Question: Difference between DSVM and Azure ML Compute Instance:
    # DSVM (Data Science Virtual Machine)
        # The DSVM is a customized VM image on the Azure Cloud platform built specifically for doing data science.
            # DSVM support Python, R, Julia, SQL, C#, Java, Node.js
            # Operating sytem support Ubuntu and Windows.
            # Allows Scale up option.
            # Without built-in hosted notebooks
            # Pre-installed tools include: Jupyter(Lab), RStudio Server, VSCode, Visual Studio, PyCharm, Juno, Power BI Desktop, SSMS, Office 365, Apache Drill.
    # Azure Machine Learning Compute Instance:
        # Azure ML Compute Instance are fully configured and managed VM image whereas DSVM is an unmanaged VM.
            # Azure ML Compute Instance only support Python and R.
            # Only works on Ubuntu.
            # Allows Scale up option.
            # With built-in hosted Notebooks.
            # Pre-installed tools only include: Jupyter(Lab), RStudio Server
    # DLVM (Deep Learning Virtial Machine)
        # DLVM is a pre-configured environment for deep learning using GPU instance.
#
# Question: Classification task, dataset is inbalanced, how to improve classification accuracy?
    # SMOTE (Synthetic Minority Oversampling Technique)
        # 200 SMOTE percentage would increase 1% minority class to around 3% (2/101)
#
#
# Question: You can move data to and from Azure Blob using different technologies include:
    # Azure Storage Explorer
    # AzCopy
    # Python/ Pyspark
    # SSIS
    
# Question: Moving a large dataset from Azure ML Studio to a Weka environment:
    
    # 
# Question: 
    # Weka: weka is used for visual data mining and machine learning software in Java.
    # Rattle: Rattle is the R analytical tool that gets you started with data analytics and machine learning.
# 

# Caffe2: 
    #
# Ubuntu:

# Question: compute target to deploy the workspace
    # Azure Container Service



# Question: what is a workspace in Azure ML?
    # 


# Question: how to deal with new data input that does not exist in the training dataset.
    # 


# Question: script to retrieve the output file names:
    # 

# Question: deploy the model to a context that allows for real-time GPU-Based inferencing:
    # Should use compute type: Azure Kubernates Service
        # For web-service deployment, GPU inferencing is only supported on Azure Kubernates Service.
        # For inferencing using a Machine Learning pipeline, GPUs are only supported on Azure Machine Learning Compute.
#
# Question: Batch inferencing, need to monitor the progress of the pipeline execution:
    # 
#
# Question: how to ensure the correct version of Pytorch can be identified for the inferencing environment when the model is deployed?
    # 
#
# Question: Need to normalize values to produce an output column into bins to predict target column:
    # Entropy MDL Bining Mode:
#
# 


# Question: Difference between Azure ML Service and Azure ML Studio?
    # 





















 
