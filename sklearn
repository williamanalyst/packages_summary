# split train and test dataset
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 21, stratify = y) #

# K-NN (K-nearest neighbors, to predict, choose the closest K points of the item to be predicted, 
    # check to which group do they belong to, and classify it to the group with highest frequency.)
        # large K = smoother decision boundary = less complex model
        # small K = more complex model = risk of over-fitting
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborClassifier(n_neighbors = 6)
knn.fit(X_train, y_train)
#
prediction = knn.predict(X_test)
knn.score(X_train, y_train) # accuracy on the training dataset
knn.score(X_test, y_test) # accuracy on the test dataset

# linear regression (ordinary least squares = minimize the sum of residual-squared )
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
#
linearreg = LinearRegression()
linearreg.fit(X_train, y_train) #
#
y_pred = linearreg.predict(X_test)
linearreg.score(X_test, y_test)
linearreg.score(X_test, y_test)
rmse = np.sqrt(mean_squared_error(y_pred, y_test)) # calculate the error/loss function value 

# K-fold cross-validation (resolve the problem that your model selection depends on the train-test split, which may accidentally form unwanted pattern)
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
#
reg = LinearRegression()
cv_score = cross_val_score(reg, X, y, cv = 5) # returns 5 results in 5 folds

# Regularization 
from sklearn.linear_model import Ridge
ridge = Ridge(alpha = 0.1, normalize = True)
ridge.fit(X, y)
#
print(righe.alpha) #

from sklearn.linear_model import Lasso # can be used to select important features of a dataset
lasso = Lasso(alpha = 0.4, normalize = True)
lasso.fit(X, y)
#
lasso_coef = lasso.coef_ # 
#


# k-means clustering
# 
from sklearn.preprocessing import StandardScaler

#
ss = StandardScaler()
df_scaled = ss.fit_transform(df_selected.astype(float)) # standardise the input variables

#
kmeans = KMeans(n_clusters = 3, random_state = 42).fit(df_scaled) # use k-means method to classify the items/observations 
labels = kmeans.labels_


# 
